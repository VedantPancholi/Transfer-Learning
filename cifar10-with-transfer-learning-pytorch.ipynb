{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3649,"databundleVersionId":46718,"sourceType":"competition"}],"dockerImageVersionId":30636,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"For the Code in Tensorflow/Keras, please refer: https://www.kaggle.com/code/priyankdl/cifar10-with-transferlearning-flow-from-directory\n\nThe following code is written in PyTorch. If you like the notebook, please upvote it.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import numpy as np \nimport pandas as pd # for reading csv file\n\n#train and test images are .7z archives, we need to unpack them\n!pip install py7zr\n\nfrom py7zr import unpack_7zarchive\nimport shutil\n\n#Before using, we need to register unpack format\nshutil.register_unpack_format('7zip', ['.7z'], unpack_7zarchive)\n\n#unpack train images in /kaggle/working or /kaggle/temp\nshutil.unpack_archive('/kaggle/input/cifar-10/train.7z', '/kaggle/temp/')","metadata":{"execution":{"iopub.status.busy":"2025-02-16T18:45:51.771486Z","iopub.execute_input":"2025-02-16T18:45:51.772284Z","iopub.status.idle":"2025-02-16T18:46:24.121072Z","shell.execute_reply.started":"2025-02-16T18:45:51.772253Z","shell.execute_reply":"2025-02-16T18:46:24.120017Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: py7zr in /opt/conda/lib/python3.10/site-packages (0.22.0)\nRequirement already satisfied: texttable in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.7.0)\nRequirement already satisfied: pycryptodomex>=3.16.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (3.21.0)\nRequirement already satisfied: pyzstd>=0.15.9 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.16.2)\nRequirement already satisfied: pyppmd<1.2.0,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.1)\nRequirement already satisfied: pybcj<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.3)\nRequirement already satisfied: multivolumefile>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from py7zr) (0.2.3)\nRequirement already satisfied: inflate64<1.1.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.0.1)\nRequirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr) (1.1.0)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from py7zr) (5.9.3)\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"import torch\nif torch.cuda.is_available():\n    device=torch.device(type=\"cuda\", index=0)\nelse:\n    device=torch.device(type=\"cpu\", index=0)            ","metadata":{"execution":{"iopub.status.busy":"2025-02-16T18:46:24.122855Z","iopub.execute_input":"2025-02-16T18:46:24.123133Z","iopub.status.idle":"2025-02-16T18:46:24.127928Z","shell.execute_reply.started":"2025-02-16T18:46:24.123111Z","shell.execute_reply":"2025-02-16T18:46:24.126919Z"},"trusted":true},"outputs":[],"execution_count":19},{"cell_type":"code","source":"#first fetching the class names from trainLabels.csv\n\ntrain_labels=pd.read_csv(\"/kaggle/input/cifar-10/trainLabels.csv\", header='infer')\n\n#unique labels\nclasses=train_labels['label'].unique()\n\n#confirming\nprint(classes)\n\n#classnames to classids\nname2num={}\ni=0\nfor name in classes:\n    name2num[name]=i\n    i=i+1\n\nnum2name={}\nfor i in range(len(classes)):\n    num2name[i]=classes[i]","metadata":{"execution":{"iopub.status.busy":"2025-02-16T18:46:24.129384Z","iopub.execute_input":"2025-02-16T18:46:24.129743Z","iopub.status.idle":"2025-02-16T18:46:24.205459Z","shell.execute_reply.started":"2025-02-16T18:46:24.129710Z","shell.execute_reply":"2025-02-16T18:46:24.204703Z"},"trusted":true},"outputs":[{"name":"stdout","text":"['frog' 'truck' 'deer' 'automobile' 'bird' 'horse' 'ship' 'cat' 'dog'\n 'airplane']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"from torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader\nimport os\nfrom torchvision.io import read_image\nfrom torchvision.transforms import ToTensor, Normalize, Resize, Compose\n\nclass TrainDataset(Dataset):\n    def __init__(self, imgpath, labelpath):\n        super().__init__()\n        self.imgpath=imgpath\n        self.labelpath=labelpath\n        self.labels=pd.read_csv(labelpath, header='infer')\n        self.transform=Compose([Resize((224,224), antialias=True), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n        \n    def __len__(self):\n        return self.labels.shape[0]\n    \n    def __getitem__(self,idx):\n        finalpath=os.path.join(self.imgpath,str(idx+1))+'.png'\n        img=read_image(finalpath)/255\n        img=self.transform(img)\n        label=self.labels.iloc[idx,1]\n        label=name2num[label]\n        return img,label\n\ntraindataset=TrainDataset('/kaggle/temp/train','/kaggle/input/cifar-10/trainLabels.csv')        \n        \nbatch_size=64    \ntraindataloader=DataLoader(dataset=traindataset, batch_size=batch_size)","metadata":{"execution":{"iopub.status.busy":"2025-02-16T18:46:24.206611Z","iopub.execute_input":"2025-02-16T18:46:24.206945Z","iopub.status.idle":"2025-02-16T18:46:24.225596Z","shell.execute_reply.started":"2025-02-16T18:46:24.206916Z","shell.execute_reply":"2025-02-16T18:46:24.224836Z"},"trusted":true},"outputs":[],"execution_count":21},{"cell_type":"code","source":"import torch.nn as nn\nfrom torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\nclass Cifar10Net(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.pretrainednet=mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.DEFAULT)\n        self.pretrainednet.classifier=nn.Sequential(\n            nn.Linear(in_features=960, out_features=1280, \n                   bias=True),nn.Hardswish(), \n            nn.Dropout(p=0.2, inplace=True), \n            nn.Linear(in_features=1280, out_features=10, \n                      bias=True)\n        )\n        \n    def forward(self,x):\n        x=self.pretrainednet(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2025-02-16T18:46:24.227246Z","iopub.execute_input":"2025-02-16T18:46:24.227473Z","iopub.status.idle":"2025-02-16T18:46:24.232558Z","shell.execute_reply.started":"2025-02-16T18:46:24.227453Z","shell.execute_reply":"2025-02-16T18:46:24.231737Z"},"trusted":true},"outputs":[],"execution_count":22},{"cell_type":"code","source":"def train_one_epoch(dataloader, model,loss_fn, optimizer):\n    model.train()\n    track_loss=0\n    num_correct=0\n    num_param=0\n    \n    for i, (imgs, labels) in enumerate(dataloader):\n        imgs=imgs.to(device)\n        labels=labels.to(device)\n        pred=model(imgs)\n                    \n        loss=loss_fn(pred,labels)\n        track_loss+=loss.item()\n        num_correct+=(torch.argmax(pred,dim=1)==labels).type(torch.float).sum().item()\n        \n        running_loss=round(track_loss/(i+(imgs.shape[0]/batch_size)),2)\n        running_acc=round((num_correct/((i*batch_size+imgs.shape[0])))*100,2)\n        \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n\n        if i%100==0:\n            print(\"Batch:\", i+1, \"/\",len(dataloader), \"Running Loss:\",running_loss, \"Running Accuracy:\",running_acc)\n            \n    epoch_loss=running_loss\n    epoch_acc=running_acc\n    return epoch_loss, epoch_acc","metadata":{"execution":{"iopub.status.busy":"2025-02-16T18:46:24.233487Z","iopub.execute_input":"2025-02-16T18:46:24.233717Z","iopub.status.idle":"2025-02-16T18:46:24.243462Z","shell.execute_reply.started":"2025-02-16T18:46:24.233698Z","shell.execute_reply":"2025-02-16T18:46:24.242888Z"},"trusted":true},"outputs":[],"execution_count":23},{"cell_type":"code","source":"model=Cifar10Net()\nmodel=model.to(device)\n\nfor param in model.pretrainednet.features.parameters():\n    param.requires_grad=False\n\nloss_fn=nn.CrossEntropyLoss()\nlr=0.001\n#optimizer=torch.optim.SGD(params=model.parameters(), lr=lr)\noptimizer=torch.optim.Adam(params=model.parameters(), lr=lr)\nn_epochs=5\n\nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,model,loss_fn,optimizer)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n    print(\"--------------------------------------------------\")\n\nfor param in model.pretrainednet.features.parameters():\n    param.requires_grad=True\n\nfor i in range(n_epochs):\n    print(\"Epoch No:\",i+1)\n    train_epoch_loss, train_epoch_acc=train_one_epoch(traindataloader,model,loss_fn,optimizer)\n    print(\"Training:\", \"Epoch Loss:\", train_epoch_loss, \"Epoch Accuracy:\", train_epoch_acc)\n    print(\"--------------------------------------------------\")","metadata":{"execution":{"iopub.status.busy":"2025-02-16T18:46:24.244300Z","iopub.execute_input":"2025-02-16T18:46:24.244522Z","iopub.status.idle":"2025-02-16T19:06:13.135153Z","shell.execute_reply.started":"2025-02-16T18:46:24.244503Z","shell.execute_reply":"2025-02-16T19:06:13.134190Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Epoch No: 1\nBatch: 1 / 782 Running Loss: 2.3 Running Accuracy: 15.62\nBatch: 101 / 782 Running Loss: 1.06 Running Accuracy: 64.43\nBatch: 201 / 782 Running Loss: 0.92 Running Accuracy: 68.23\nBatch: 301 / 782 Running Loss: 0.87 Running Accuracy: 69.95\nBatch: 401 / 782 Running Loss: 0.83 Running Accuracy: 71.21\nBatch: 501 / 782 Running Loss: 0.81 Running Accuracy: 71.78\nBatch: 601 / 782 Running Loss: 0.8 Running Accuracy: 72.16\nBatch: 701 / 782 Running Loss: 0.79 Running Accuracy: 72.62\nTraining: Epoch Loss: 0.78 Epoch Accuracy: 72.99\n--------------------------------------------------\nEpoch No: 2\nBatch: 1 / 782 Running Loss: 0.62 Running Accuracy: 75.0\nBatch: 101 / 782 Running Loss: 0.67 Running Accuracy: 76.7\nBatch: 201 / 782 Running Loss: 0.64 Running Accuracy: 77.11\nBatch: 301 / 782 Running Loss: 0.64 Running Accuracy: 77.49\nBatch: 401 / 782 Running Loss: 0.64 Running Accuracy: 77.67\nBatch: 501 / 782 Running Loss: 0.64 Running Accuracy: 77.64\nBatch: 601 / 782 Running Loss: 0.64 Running Accuracy: 77.65\nBatch: 701 / 782 Running Loss: 0.63 Running Accuracy: 77.68\nTraining: Epoch Loss: 0.63 Epoch Accuracy: 77.8\n--------------------------------------------------\nEpoch No: 3\nBatch: 1 / 782 Running Loss: 0.56 Running Accuracy: 78.12\nBatch: 101 / 782 Running Loss: 0.59 Running Accuracy: 78.91\nBatch: 201 / 782 Running Loss: 0.57 Running Accuracy: 79.59\nBatch: 301 / 782 Running Loss: 0.56 Running Accuracy: 79.82\nBatch: 401 / 782 Running Loss: 0.56 Running Accuracy: 79.96\nBatch: 501 / 782 Running Loss: 0.56 Running Accuracy: 79.97\nBatch: 601 / 782 Running Loss: 0.56 Running Accuracy: 80.01\nBatch: 701 / 782 Running Loss: 0.56 Running Accuracy: 80.1\nTraining: Epoch Loss: 0.56 Epoch Accuracy: 80.26\n--------------------------------------------------\nEpoch No: 4\nBatch: 1 / 782 Running Loss: 0.5 Running Accuracy: 81.25\nBatch: 101 / 782 Running Loss: 0.52 Running Accuracy: 81.71\nBatch: 201 / 782 Running Loss: 0.5 Running Accuracy: 82.26\nBatch: 301 / 782 Running Loss: 0.49 Running Accuracy: 82.56\nBatch: 401 / 782 Running Loss: 0.49 Running Accuracy: 82.56\nBatch: 501 / 782 Running Loss: 0.49 Running Accuracy: 82.78\nBatch: 601 / 782 Running Loss: 0.49 Running Accuracy: 82.79\nBatch: 701 / 782 Running Loss: 0.48 Running Accuracy: 82.91\nTraining: Epoch Loss: 0.48 Epoch Accuracy: 83.13\n--------------------------------------------------\nEpoch No: 5\nBatch: 1 / 782 Running Loss: 0.39 Running Accuracy: 82.81\nBatch: 101 / 782 Running Loss: 0.43 Running Accuracy: 84.61\nBatch: 201 / 782 Running Loss: 0.42 Running Accuracy: 85.05\nBatch: 301 / 782 Running Loss: 0.41 Running Accuracy: 85.55\nBatch: 401 / 782 Running Loss: 0.41 Running Accuracy: 85.69\nBatch: 501 / 782 Running Loss: 0.4 Running Accuracy: 85.94\nBatch: 601 / 782 Running Loss: 0.4 Running Accuracy: 86.05\nBatch: 701 / 782 Running Loss: 0.39 Running Accuracy: 86.25\nTraining: Epoch Loss: 0.39 Epoch Accuracy: 86.47\n--------------------------------------------------\nEpoch No: 1\nBatch: 1 / 782 Running Loss: 0.32 Running Accuracy: 89.06\nBatch: 101 / 782 Running Loss: 0.61 Running Accuracy: 80.32\nBatch: 201 / 782 Running Loss: 0.52 Running Accuracy: 83.01\nBatch: 301 / 782 Running Loss: 0.48 Running Accuracy: 84.36\nBatch: 401 / 782 Running Loss: 0.44 Running Accuracy: 85.43\nBatch: 501 / 782 Running Loss: 0.41 Running Accuracy: 86.31\nBatch: 601 / 782 Running Loss: 0.4 Running Accuracy: 86.84\nBatch: 701 / 782 Running Loss: 0.38 Running Accuracy: 87.36\nTraining: Epoch Loss: 0.37 Epoch Accuracy: 87.64\n--------------------------------------------------\nEpoch No: 2\nBatch: 1 / 782 Running Loss: 0.14 Running Accuracy: 93.75\nBatch: 101 / 782 Running Loss: 0.23 Running Accuracy: 91.82\nBatch: 201 / 782 Running Loss: 0.23 Running Accuracy: 92.16\nBatch: 301 / 782 Running Loss: 0.22 Running Accuracy: 92.72\nBatch: 401 / 782 Running Loss: 0.21 Running Accuracy: 93.08\nBatch: 501 / 782 Running Loss: 0.2 Running Accuracy: 93.29\nBatch: 601 / 782 Running Loss: 0.2 Running Accuracy: 93.33\nBatch: 701 / 782 Running Loss: 0.19 Running Accuracy: 93.45\nTraining: Epoch Loss: 0.19 Epoch Accuracy: 93.44\n--------------------------------------------------\nEpoch No: 3\nBatch: 1 / 782 Running Loss: 0.12 Running Accuracy: 96.88\nBatch: 101 / 782 Running Loss: 0.14 Running Accuracy: 94.91\nBatch: 201 / 782 Running Loss: 0.15 Running Accuracy: 94.78\nBatch: 301 / 782 Running Loss: 0.15 Running Accuracy: 94.8\nBatch: 401 / 782 Running Loss: 0.14 Running Accuracy: 94.93\nBatch: 501 / 782 Running Loss: 0.14 Running Accuracy: 94.97\nBatch: 601 / 782 Running Loss: 0.14 Running Accuracy: 95.0\nBatch: 701 / 782 Running Loss: 0.14 Running Accuracy: 95.1\nTraining: Epoch Loss: 0.14 Epoch Accuracy: 95.12\n--------------------------------------------------\nEpoch No: 4\nBatch: 1 / 782 Running Loss: 0.16 Running Accuracy: 95.31\nBatch: 101 / 782 Running Loss: 0.13 Running Accuracy: 95.3\nBatch: 201 / 782 Running Loss: 0.14 Running Accuracy: 95.17\nBatch: 301 / 782 Running Loss: 0.13 Running Accuracy: 95.27\nBatch: 401 / 782 Running Loss: 0.13 Running Accuracy: 95.26\nBatch: 501 / 782 Running Loss: 0.13 Running Accuracy: 95.3\nBatch: 601 / 782 Running Loss: 0.13 Running Accuracy: 95.42\nBatch: 701 / 782 Running Loss: 0.13 Running Accuracy: 95.48\nTraining: Epoch Loss: 0.13 Epoch Accuracy: 95.53\n--------------------------------------------------\nEpoch No: 5\nBatch: 1 / 782 Running Loss: 0.13 Running Accuracy: 93.75\nBatch: 101 / 782 Running Loss: 0.12 Running Accuracy: 96.09\nBatch: 201 / 782 Running Loss: 0.11 Running Accuracy: 96.05\nBatch: 301 / 782 Running Loss: 0.12 Running Accuracy: 96.01\nBatch: 401 / 782 Running Loss: 0.11 Running Accuracy: 96.14\nBatch: 501 / 782 Running Loss: 0.11 Running Accuracy: 96.15\nBatch: 601 / 782 Running Loss: 0.11 Running Accuracy: 96.29\nBatch: 701 / 782 Running Loss: 0.1 Running Accuracy: 96.36\nTraining: Epoch Loss: 0.1 Epoch Accuracy: 96.38\n--------------------------------------------------\n","output_type":"stream"}],"execution_count":24},{"cell_type":"code","source":"class TestDataset(Dataset):\n    def __init__(self, imgpath):\n        super().__init__()\n        self.imgpath=imgpath\n        _,_,self.files=next(os.walk(self.imgpath))\n        self.length=len(self.files)\n        self.transform=Compose([Resize((224,224), antialias=True), Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])        \n    \n    def __len__(self):\n        return self.length\n    \n    def __getitem__(self,idx):\n        finalpath=os.path.join(self.imgpath,str(idx+1))+'.png'\n        img=read_image(finalpath)/255.0\n        img=self.transform(img)\n        return img\n\ntestdataset=TestDataset('/kaggle/temp/test/')\ntestdataloader=DataLoader(dataset=testdataset, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T19:08:30.213568Z","iopub.execute_input":"2025-02-16T19:08:30.213907Z","iopub.status.idle":"2025-02-16T19:08:30.517767Z","shell.execute_reply.started":"2025-02-16T19:08:30.213878Z","shell.execute_reply":"2025-02-16T19:08:30.517005Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"def eval(dataloader, model,loss_fn, path):\n    model.eval()\n    data=pd.read_csv(path)\n    with torch.no_grad():\n        for i, imgs in enumerate(dataloader):\n            finalbatchpred=np.zeros(imgs.shape[0],dtype='object')\n            imgs=imgs.to(device)\n            pred=model(imgs)\n            \n            pred=torch.argmax(pred,dim=1).type(torch.int).cpu()\n            for j,p in enumerate(pred):\n                finalbatchpred[j]=num2name[p.item()]\n            data.iloc[i*batch_size:i*batch_size+batch_size ,1]=finalbatchpred\n    \n    data.to_csv('submission.csv', index=False)\n    data.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T19:08:30.518805Z","iopub.execute_input":"2025-02-16T19:08:30.519132Z","iopub.status.idle":"2025-02-16T19:08:30.654971Z","shell.execute_reply.started":"2025-02-16T19:08:30.519092Z","shell.execute_reply":"2025-02-16T19:08:30.654193Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"eval(testdataloader, model,loss_fn, '/kaggle/input/cifar-10/sampleSubmission.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-16T19:08:30.655918Z","iopub.execute_input":"2025-02-16T19:08:30.656172Z","iopub.status.idle":"2025-02-16T19:17:22.253541Z","shell.execute_reply.started":"2025-02-16T19:08:30.656130Z","shell.execute_reply":"2025-02-16T19:17:22.252497Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"If you liked the notebook, please upvote it.","metadata":{}}]}